{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12c3daa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lz/81hq8_d56pjbxtvpn4bqw7hm0000gn/T/ipykernel_69173/82144332.py:24: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  trades['price_log_return'] = trades.groupby(['time_id', 'stock_id'])['price'].apply(log_return)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of the XGBoost model with feature engineering: R2 score: 0.879, RMSPE: 0.197\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "\n",
    "def log_return(list_stock_prices):\n",
    "    return np.log(list_stock_prices).diff()\n",
    "\n",
    "def realized_volatility(series_log_return):\n",
    "    return np.sqrt(np.sum(series_log_return**2))\n",
    "\n",
    "def rmspe(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square((y_true - y_pred) / y_true)))\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "book = pd.read_parquet('order_book_feature.parquet')\n",
    "trades = pd.read_parquet('trades.parquet')\n",
    "\n",
    "book['wap'] = (book['bid_price1'] * book['ask_size1'] + book['ask_price1'] * book['bid_size1']) / (book['bid_size1'] + book['ask_size1'])\n",
    "book['bid_ask_spread'] = book['ask_price1'] - book['bid_price1']\n",
    "book['order_imbalance'] = (book['bid_size1'] - book['ask_size1']) / (book['bid_size1'] + book['ask_size1'])\n",
    "\n",
    "trades['price_log_return'] = trades.groupby(['time_id', 'stock_id'])['price'].apply(log_return)\n",
    "trades = trades.dropna()\n",
    "\n",
    "features = book.groupby(['time_id', 'stock_id']).agg({\n",
    "    'wap': 'mean',\n",
    "    'bid_ask_spread': 'mean',\n",
    "    'order_imbalance': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "trades_features = trades.groupby(['time_id', 'stock_id']).agg({\n",
    "    'price_log_return': [realized_volatility],\n",
    "    'size': 'sum',\n",
    "    'order_count': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "trades_features.columns = ['_'.join(col) if col[0] != 'time_id' and col[0] != 'stock_id' else col[0] for col in trades_features.columns.values]\n",
    "\n",
    "merged_features = pd.merge(features, trades_features, on=['time_id', 'stock_id'], how='left')\n",
    "\n",
    "train_merged = train.merge(merged_features, on=['stock_id', 'time_id'], how='left')\n",
    "\n",
    "X = train_merged.drop(['target', 'time_id', 'stock_id'], axis=1)\n",
    "y = train_merged['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = xgb.XGBRegressor(objective='reg:squarederror', n_jobs=-1, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "R2 = round(r2_score(y_true=y_test, y_pred=y_pred), 3)\n",
    "RMSPE = round(rmspe(y_true=y_test, y_pred=y_pred), 3)\n",
    "\n",
    "print(f'Performance of the XGBoost model with feature engineering: R2 score: {R2}, RMSPE: {RMSPE}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd995cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "\n",
    "# Existing functions...\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "book = pd.read_parquet('order_book_feature.parquet')\n",
    "trades = pd.read_parquet('trades.parquet')\n",
    "time_id_reference = pd.read_csv('time_id_reference.csv')\n",
    "\n",
    "# Parse date and time\n",
    "time_id_reference['datetime'] = pd.to_datetime(time_id_reference['date'] + ' ' + time_id_reference['time'])\n",
    "time_id_reference = time_id_reference.drop(['date', 'time'], axis=1)\n",
    "\n",
    "# Extract time features\n",
    "time_id_reference['hour'] = time_id_reference['datetime'].dt.hour\n",
    "time_id_reference['weekday'] = time_id_reference['datetime'].dt.weekday\n",
    "time_id_reference['week'] = time_id_reference['datetime'].dt.isocalendar().week.astype(int)\n",
    "time_id_reference['month'] = time_id_reference['datetime'].dt.month\n",
    "\n",
    "# Merge time_id_reference with train\n",
    "train = train.merge(time_id_reference, on='time_id', how='left')\n",
    "\n",
    "# Calculate features from book and trades...\n",
    "\n",
    "# Merge the features\n",
    "merged_features = pd.merge(features, trades_features, on=['time_id', 'stock_id'], how='left')\n",
    "\n",
    "train_merged = train.merge(merged_features, on=['stock_id', 'time_id'], how='left')\n",
    "\n",
    "X = train_merged.drop(['target', 'time_id', 'stock_id', 'datetime'], axis=1)\n",
    "y = train_merged['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = xgb.XGBRegressor(objective='reg:squarederror', n_jobs=-1, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "R2 = round(r2_score(y_true=y_test, y_pred=y_pred), 3)\n",
    "RMSPE = round(rmspe(y_true=y_test, y_pred=y_pred), 3)\n",
    "\n",
    "print(f'Performance of the XGBoost model with time-based features: R2 score: {R2}, RMSPE: {RMSPE}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7086cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "book = pd.read_parquet('order_book_feature.parquet')\n",
    "\n",
    "book['wap'] = (book['bid_price1'] * book['ask_size1'] + book['ask_price1'] * book['bid_size1']) / (book['bid_size1'] + book['ask_size1'])\n",
    "\n",
    "def log_return(list_stock_prices):\n",
    "    return np.log(list_stock_prices).diff()\n",
    "\n",
    "def realized_volatility(series_log_return):\n",
    "    return np.sqrt(np.sum(series_log_return**2))\n",
    "\n",
    "def realized_volatility_per_time_id(df_book_data):\n",
    "    df_book_data['log_return'] = df_book_data.groupby(['time_id', 'stock_id'])['wap'].apply(log_return)\n",
    "    df_book_data = df_book_data[~df_book_data['log_return'].isnull()]\n",
    "    df_realized_vol_per_stock = pd.DataFrame(df_book_data.groupby(['stock_id', 'time_id'])['log_return'].agg(realized_volatility)).reset_index()\n",
    "    df_realized_vol_per_stock = df_realized_vol_per_stock.rename(columns={'log_return': 'realized_vol'})\n",
    "    return df_realized_vol_per_stock\n",
    "\n",
    "df_past_realized_train = realized_volatility_per_time_id(book)\n",
    "\n",
    "# Calculate the moving average of past realized volatilities\n",
    "window_size = 5\n",
    "df_past_realized_train['moving_average_vol'] = df_past_realized_train.groupby('stock_id')['realized_vol'].rolling(window=window_size).mean().reset_index(level=0, drop=True)\n",
    "\n",
    "df_joined = train.merge(df_past_realized_train, on=['stock_id', 'time_id'], how='left')\n",
    "\n",
    "# If the moving average is not available (e.g., due to lack of past data), use the realized volatility as the prediction\n",
    "df_joined['prediction'] = df_joined['moving_average_vol'].fillna(df_joined['realized_vol'])\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def rmspe(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square((y_true - y_pred) / y_true)))\n",
    "\n",
    "R2 = round(r2_score(y_true=df_joined['target'], y_pred=df_joined['prediction']), 3)\n",
    "RMSPE = round(rmspe(y_true=df_joined['target'], y_pred=df_joined['prediction']), 3)\n",
    "\n",
    "print(f'Performance of the moving average prediction: R2 score: {R2}, RMSPE: {RMSPE}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5dd8ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "book = pd.read_parquet('order_book_feature.parquet')\n",
    "\n",
    "book['wap'] = (book['bid_price1'] * book['ask_size1'] + book['ask_price1'] * book['bid_size1']) / (book['bid_size1'] + book['ask_size1'])\n",
    "\n",
    "def log_return(list_stock_prices):\n",
    "    return np.log(list_stock_prices).diff()\n",
    "\n",
    "def realized_volatility(series_log_return):\n",
    "    return np.sqrt(np.sum(series_log_return**2))\n",
    "\n",
    "def realized_volatility_per_time_id(df_book_data):\n",
    "    df_book_data['log_return'] = df_book_data.groupby(['time_id', 'stock_id'])['wap'].apply(log_return)\n",
    "    df_book_data = df_book_data[~df_book_data['log_return'].isnull()]\n",
    "    df_realized_vol_per_stock = pd.DataFrame(df_book_data.groupby(['stock_id', 'time_id'])['log_return'].agg(realized_volatility)).reset_index()\n",
    "    df_realized_vol_per_stock = df_realized_vol_per_stock.rename(columns={'log_return': 'realized_vol'})\n",
    "    return df_realized_vol_per_stock\n",
    "\n",
    "# Calculate order book skewness\n",
    "book['skewness'] = (book['bid_size1'] - book['ask_size1']) / (book['bid_size1'] + book['ask_size1'])\n",
    "\n",
    "# Calculate average skewness per stock and time_id\n",
    "book_skewness = book.groupby(['stock_id', 'time_id'])['skewness'].mean().reset_index()\n",
    "\n",
    "df_past_realized_train = realized_volatility_per_time_id(book)\n",
    "\n",
    "# Calculate the moving average of past realized volatilities\n",
    "window_size = 5\n",
    "df_past_realized_train['moving_average_vol'] = df_past_realized_train.groupby('stock_id')['realized_vol'].rolling(window=window_size).mean().reset_index(level=0, drop=True)\n",
    "\n",
    "df_joined = train.merge(df_past_realized_train, on=['stock_id', 'time_id'], how='left')\n",
    "df_joined = df_joined.merge(book_skewness, on=['stock_id', 'time_id'], how='left')\n",
    "\n",
    "# If the moving average is not available (e.g., due to lack of past data), use the realized volatility as the prediction\n",
    "df_joined['prediction'] = df_joined['moving_average_vol'].fillna(df_joined['realized_vol'])\n",
    "\n",
    "# Incorporate skewness into the prediction by adding a weight to the moving average\n",
    "skewness_weight = 0.1\n",
    "df_joined['prediction'] = df_joined['prediction'] * (1 + skewness_weight * df_joined['skewness'])\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def rmspe(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square((y_true - y_pred) / y_true)))\n",
    "\n",
    "R2 = round(r2_score(y_true=df_joined['target'], y_pred=df_joined['prediction']), 3)\n",
    "RMSPE = round(rmspe(y_true=df_joined['target'], y_pred=df_joined['prediction']), 3)\n",
    "\n",
    "print(f'Performance of the moving average prediction: R2 score: {R2}, RMSPE: {RMSPE}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2593f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "book = pd.read_parquet('order_book_feature.parquet')\n",
    "\n",
    "book['wap'] = (book['bid_price1'] * book['ask_size1'] + book['ask_price1'] * book['bid_size1']) / (book['bid_size1'] + book['ask_size1'])\n",
    "\n",
    "def log_return(list_stock_prices):\n",
    "    return np.log(list_stock_prices).diff()\n",
    "\n",
    "def realized_volatility(series_log_return):\n",
    "    return np.sqrt(np.sum(series_log_return**2))\n",
    "\n",
    "def realized_volatility_per_time_id(df_book_data):\n",
    "    df_book_data['log_return'] = df_book_data.groupby(['time_id', 'stock_id'])['wap'].apply(log_return)\n",
    "    df_book_data = df_book_data[~df_book_data['log_return'].isnull()]\n",
    "    df_realized_vol_per_stock = pd.DataFrame(df_book_data.groupby(['stock_id', 'time_id'])['log_return'].agg(realized_volatility)).reset_index()\n",
    "    df_realized_vol_per_stock = df_realized_vol_per_stock.rename(columns={'log_return': 'realized_vol'})\n",
    "    return df_realized_vol_per_stock\n",
    "\n",
    "df_past_realized_train = realized_volatility_per_time_id(book)\n",
    "\n",
    "# Calculate the exponential weighted moving average of past realized volatilities\n",
    "ewma_alpha = 0.1\n",
    "df_past_realized_train['ewma_vol'] = df_past_realized_train.groupby('stock_id')['realized_vol'].transform(lambda x: x.ewm(alpha=ewma_alpha).mean())\n",
    "\n",
    "df_joined = train.merge(df_past_realized_train, on=['stock_id', 'time_id'], how='left')\n",
    "\n",
    "# If the EWMA is not available (e.g., due to lack of past data), use the realized volatility as the prediction\n",
    "df_joined['prediction'] = df_joined['ewma_vol'].fillna(df_joined['realized_vol'])\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def rmspe(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square((y_true - y_pred) / y_true)))\n",
    "\n",
    "R2 = round(r2_score(y_true=df_joined['target'], y_pred=df_joined['prediction']), 3)\n",
    "RMSPE = round(rmspe(y_true=df_joined['target'], y_pred=df_joined['prediction']), 3)\n",
    "\n",
    "print(f'Performance of the exponential weighted moving average prediction: R2 score: {R2}, RMSPE: {RMSPE}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5f7f2c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lz/81hq8_d56pjbxtvpn4bqw7hm0000gn/T/ipykernel_69173/520252758.py:17: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id', 'stock_id'])['wap'].apply(log_return)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of the exponential weighted moving average and seasonality prediction: R2 score: 0.663, RMSPE: 0.488\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "book = pd.read_parquet('order_book_feature.parquet')\n",
    "time_id_reference = pd.read_csv('time_id_reference.csv')\n",
    "\n",
    "book['wap'] = (book['bid_price1'] * book['ask_size1'] + book['ask_price1'] * book['bid_size1']) / (book['bid_size1'] + book['ask_size1'])\n",
    "\n",
    "def log_return(list_stock_prices):\n",
    "    return np.log(list_stock_prices).diff()\n",
    "\n",
    "def realized_volatility(series_log_return):\n",
    "    return np.sqrt(np.sum(series_log_return**2))\n",
    "\n",
    "def realized_volatility_per_time_id(df_book_data):\n",
    "    df_book_data['log_return'] = df_book_data.groupby(['time_id', 'stock_id'])['wap'].apply(log_return)\n",
    "    df_book_data = df_book_data[~df_book_data['log_return'].isnull()]\n",
    "    df_realized_vol_per_stock = pd.DataFrame(df_book_data.groupby(['stock_id', 'time_id'])['log_return'].agg(realized_volatility)).reset_index()\n",
    "    df_realized_vol_per_stock = df_realized_vol_per_stock.rename(columns={'log_return': 'realized_vol'})\n",
    "    return df_realized_vol_per_stock\n",
    "\n",
    "df_past_realized_train = realized_volatility_per_time_id(book)\n",
    "\n",
    "# Calculate the exponential weighted moving average of past realized volatilities\n",
    "ewma_alpha = 0.1\n",
    "df_past_realized_train['ewma_vol'] = df_past_realized_train.groupby('stock_id')['realized_vol'].transform(lambda x: x.ewm(alpha=ewma_alpha).mean())\n",
    "\n",
    "# Merge time_id_reference to get the hour of the day\n",
    "df_past_realized_train = df_past_realized_train.merge(time_id_reference, on='time_id')\n",
    "\n",
    "# Calculate the average realized volatility per hour of the day\n",
    "df_past_realized_train['hour'] = pd.to_datetime(df_past_realized_train['time']).dt.hour\n",
    "hourly_volatility = df_past_realized_train.groupby('hour')['realized_vol'].mean().reset_index()\n",
    "\n",
    "df_joined = train.merge(df_past_realized_train, on=['stock_id', 'time_id'], how='left')\n",
    "df_joined = df_joined.merge(hourly_volatility, on='hour', how='left', suffixes=('', '_hourly'))\n",
    "\n",
    "# If the EWMA is not available (e.g., due to lack of past data), use the realized volatility as the prediction\n",
    "df_joined['prediction'] = df_joined['ewma_vol'].fillna(df_joined['realized_vol'])\n",
    "\n",
    "# Incorporate seasonality (hourly volatility) into the prediction by adding a weight\n",
    "seasonality_weight = 0.1\n",
    "df_joined['prediction'] = df_joined['prediction'] * (1 + seasonality_weight * (df_joined['realized_vol_hourly'] / df_joined['prediction']))\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def rmspe(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square((y_true - y_pred) / y_true)))\n",
    "\n",
    "R2 = round(r2_score(y_true=df_joined['target'], y_pred=df_joined['prediction']), 3)\n",
    "RMSPE = round(rmspe(y_true=df_joined['target'], y_pred=df_joined['prediction']), 3)\n",
    "print(f'Performance of the exponential weighted moving average and seasonality prediction: R2 score: {R2}, RMSPE: {RMSPE}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95dd684",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def log_return(list_stock_prices):\n",
    "    return np.log(list_stock_prices).diff()\n",
    "\n",
    "def realized_volatility(series_log_return):\n",
    "    return np.sqrt(np.sum(series_log_return**2))\n",
    "\n",
    "def generate_features(df):\n",
    "    df['bid_ask_spread'] = df['ask_price1'] - df['bid_price1']\n",
    "    df['order_imbalance'] = (df['bid_size1'] - df['ask_size1']) / (df['bid_size1'] + df['ask_size1'])\n",
    "    return df\n",
    "\n",
    "def rmspe(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square((y_true - y_pred) / y_true)))\n",
    "\n",
    "class EMATransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, alpha):\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X_ema = X.ewm(alpha=self.alpha).mean()\n",
    "        return X_ema\n",
    "\n",
    "# Load data and preprocess\n",
    "book = pd.read_parquet('order_book_feature.parquet')\n",
    "book = generate_features(book)\n",
    "\n",
    "book['wap'] = (book['bid_price1'] * book['ask_size1'] + book['ask_price1'] * book['bid_size1']) / (book['bid_size1'] + book['ask_size1'])\n",
    "\n",
    "\n",
    "book['log_return'] = book.groupby(['time_id', 'stock_id'])['wap'].apply(log_return).fillna(0)\n",
    "\n",
    "\n",
    "# Define EMA parameters\n",
    "ewma_alpha = 0.1\n",
    "df_past_realized_train['ewma_vol'] = df_past_realized_train.groupby('stock_id')['realized_vol'].transform(lambda x: x.ewm(alpha=ewma_alpha).mean())\n",
    "\n",
    "# Aggregate features and target\n",
    "agg_features = ['ewma_vol', 'bid_ask_spread', 'order_imbalance']\n",
    "agg_df = book.groupby(['stock_id', 'time_id'])[agg_features].mean().reset_index()\n",
    "agg_df['target'] = book.groupby(['stock_id', 'time_id'])['log_return'].agg(realized_volatility).reset_index(drop=True)\n",
    "\n",
    "# Train-test split\n",
    "train_df = agg_df.sample(frac=0.8, random_state=42)\n",
    "test_df = agg_df.drop(train_df.index)\n",
    "\n",
    "# Train linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(train_df[agg_features], train_df['target'])\n",
    "\n",
    "# Predict and evaluate\n",
    "preds = model.predict(test_df[agg_features])\n",
    "RMSPE_score = rmspe(test_df['target'], preds)\n",
    "\n",
    "# Calculate R^2 score\n",
    "R2 = r2_score(test_df['target'], preds)\n",
    "\n",
    "print(f'R^2: {R2:.4f}')\n",
    "print(f'RMSPE: {RMSPE_score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4986f3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
